
	
	\section{Related Work}
    Our work builds upon the following foundations, while qualitatively differing from each.

    \FIXME{ZW: I will fix this section next week.} 
	\cparagraph{Graph Convolutional Networks}
	Recently, there is an increasing interest in extending neural networks to deal with arbitrarily structured graphs and there have been
many encouraging works. Among them, GCNs~\cite{Duvenaud2015Convolutional,Kipf2016Semi,Kearnes2016Molecular}, a recent class of multilayer
neural networks operating on graphs, have been successfully applied to semi-supervised node classification~\cite{Kipf2016Semi}, semantic
role labeling~\cite{Marcheggiani2017Encoding}, neural machine translation~\cite{Bastings2017Graph} and so on.


	\cparagraph{Relational Graph Convolutional Networks}
	Since GCNs~\cite{Kipf2016Semi} generally operate on undirected and unlabeled graphs, R-GCNs~\cite{Schlichtkrull2017Modeling} are
developed specifically for relational (directed and labeled) multi-graphs to deal with the highly multi-relational data characteristic of
realistic knowledge graphs. And this model has been successfully exploited in two standard knowledge base completion tasks: Link prediction
and entity classification~\cite{Schlichtkrull2017Modeling}. In this paper, we successfully construct the entity alignment model which
utilizes R-GCNs to embed entities of multiple KGs into a unified vector space.
	
	\cparagraph{Entity Alignment}
	Here we provide a systematic review of current work on entity alignment.
	
	As we mentioned in Section~\ref{section:intro}, the conventional entity alignment approaches are usually time-consuming and laborious since that the traditional works generally rely on external information and require costly manual feature construction. For example, in the work of Wang Xuepeng et al.~\shortcite{Wang2017}, they need to collect various network semantic labels such as category labels, attribute labels and unstructured text keywords of the entity entries to build a number of semantic similarity calculation models.
	
	To address these issues, several embedding-based methods have been proposed and achieve promising results.
	
	JE~\cite{hao2016joint} jointly learns the embeddings of different KGs in a uniform vector space, following the energy-based framework in TransE, and align entities in KGs by adding the loss of alignment part to the global loss function. In the learning process, JE requires the seed aligned entities share the same embeddings.
	
	MTransE~\cite{chen2016multilingual} is also a TransE-based model for cross-lingual KG alignment. It embeds entities and relations of each language in a separated embedding space and also provides transitions for each embedding vector to its cross-lingual counterparts in other spaces. For model training, MTransE needs a set of triples to be aligned in advance.
	
	JAPE~\cite{sun2017cross} is a joint attribute-preserving embedding model, based on TransE, for cross-lingual entity alignment. And JAPE proposed attribute embedding to represent the attribute correlations of KGs which considers the value information, only the type of values. JAPE needs both relations and attributes to be aligned in advance.
	
	ITransE~\cite{zhu2017iterative} jointly encodes both entities and relations of multiple KGs into a unified semantic space according to a seed set of aligned entities. ITransE utilizes the newly aligned entities to update joint embeddings to achieve iterative entity alignment. Besides pre-aligned entities, ITransE requires all relations being shared among KGs.
	
	Since utilizing TransE to embed entities, JE, MTransE, JAPE and ITransE might not perform well under several tough situations and these embedding-based approaches all ignored the specific attribute values as mentioned in Section~\ref{section:intro}. In addition, the seed alignments required by MTransE, JAPE and ITransE are difficult to obtain in practice.
	
	Instead of utilizing TransE, our approach leverages R-GCNs~\cite{Schlichtkrull2017Modeling} to better characterize entities by incorporating the neighboring relational structure information and considers the specific value information in multiple KGs.
