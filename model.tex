\section{Our Approach}
	\label{section:app}
	Our work aims to develop an entity alignment model for any two arbitrary (heterogeneous) \KGs. Without loss of generality, we
introduce our approach using two \KGs: $G_1 = (E_1,V_1,R_1,A_1,T_1)$ and $G_2 = (E_2,V_2,R_2,A_2,T_2)$ for entity alignment, where
$E,V,R,A,T$ represent entities, values, relations, attributes and triples respectively. 	We put $G_1$ and $G_2$ together in one large
graph $G$. We utilize pre-aligned entity pairs to train our models and then discover new equivalent entities. Figure~\ref{all} demonstrates
the overall architecture of our model. 	
	
	\begin{figure}[t!]
		\centering
			\includegraphics[width=0.8\linewidth]{figures/graph2.pdf}
			\caption{Overall architecture of our entity alignment model.}
            \FIXME{ZW: What is $d_s$ in the diagram? This is not mentioned in the text.}
			\label{all}
	\end{figure}
	
    \subsection{Base Model}
    Our approach is based on the recently proposed relational graph convolutional network (\RGCN)~\cite{Schlichtkrull2017Modeling}.
    \RGCN is an extension of Graph Convolutional Networks (\GCNs) that operate on local graph neighborhoods~\cite{Duvenaud2015Convolutional,Kipf2016Semi} to large-scale relational data.
    A \RGCN takes a set of adjacency matrices as input, and produces a new set of node features.
    Each input adjacency matrix describes the adjacency relationships among all nodes in the graph under each different relation.
    We choose to use \RGCN because it can model relational (directed and labeled) multi-graphs like \KGs.


 Our work improves \RGCNs in two ways. Firstly, we introduce highways to reduce the impact of noise.
    Secondly, we use automatically learned semantic features such as entity names and attributes to to help the \RGCN to better capture the
    subtle correlations between two \KGs.


 %   Our work improves the featureless approach of \RGCN with pre-defined node feature vectors.
%    We believe that in addition to the internal structures, the semantic information of entity names and the attribute information of entities can help \RGCN better embed \KGs.
%    Therefore, we incorporate the aforementioned information into the node features as part of the model inputs.


	
	
	\subsection{Our R-GCN-based Entity Alignment Model}
	\label{section:rgcn}	
  %  The input to our RGCN model are two parts. The first part is the node feature matrix $X^{(0)} \in \mathbb{R}^{N \times d^{(0)}}$ of $G$, where $N$ is the number of nodes and $d^{(0)}$ is the dimension of the input representations. We utilize predefined node features described in Section~\ref{subsection:Node Representations} to construct $X$ instead of using a featureless approach in \RGCNs~\cite{Schlichtkrull2017Modeling}.
%	The second part is the list of adjacency matrices $A=\{A_1,A_2,...,A_R |A_i \in \mathbb{R}^{N \times N} \}$, which describes the adjacency relationships among $N$ nodes under $R$ different relations. We extract $R_0$ original relations from knowledge graphs, then we add reverse relations in order to pass information from the opposite direction; and add the self loop to retain information of the node itself. These together compose $R=2R_0+1$ relations.
%	In each layer $l$, the input is $X^{(l)} = \{x^{(l)}_1,x^{(l)}_2,...,x^{(l)}_{N} |x^{(l)}_{i} \in \mathbb{R}^{d^{(l)}}\}$. The forward propagation is formulated as:


    Figure~\ref{all} depicts our entity alignment model which is a stack of two \RGCNs.
  	The input to each \RGCN consists of two parts: (i) a node feature matrix that captures the semantic information such as the entity
  names and their attributes, and (ii) a list of adjacency matrices, which describes the adjacency relationships among nodes of a \KG.

  \FIXME{ZW: This section is so confusing. I have tried to rewrite it. Please double check.}

%
% We utilize predefined node features
% described in Section~\ref{subsection:Node Representations} to construct $X$ to capture the semantic information. 	The second part is

\subsubsection{i. Node representations}
	\label{subsection:Node Representations}
   We use a node feature matrix, $X^{(0)} \in \mathbb{R}^{N \times d^{(0)}}$ of $G$, to encode the semantic information of $N$  nodes in a $d^{(0)}$ dimensional input representation vector.
   This input directs the \RGCN to draw attention to the entity names and attributes, which are shown to be useful in entity
   alignment (Section~\ref{sec:motivation}). We stress that this node feature matrix is automatically initialized and updated during training.

	
	\eparagraph{Semantic information}
	\label{wordvector}
	Intuitively, if two entities can be linked together, their names in different \KGs should have similar semantics (e.g., the \emph{XinJiang} entity in Section~\ref{sec:motivation}).
    Our work exploits this observation to improve the quality of the network features by using pre-trained word embeddings to encode the semantic
    information entity names. This is achieved by applying a word2vec model to generate word embeddings from training entity names.
    %We use an open-source word2vec implementaion\footnote{https://code.google.com/archive/p/word2vec} to generate word embeddings.

	
	\eparagraph{Attribute information}
    In addition to entity names, we also consider entity attributes for node representations.
	Our current implementation distinguishes four types of attributes, i.e., \emph{Integer}, \emph{Double}, \emph{Date} and \emph{String}
(as default), but other data types can be added into the model.
	%In this paper, we only consider the first three types, i.e., Integer, Double and Date.
%	We overlook String type values by reason of their complexity and heterogeneity in different \KGs.
%	
	We construct normalized attribute vector for each entity. The dimension of an attribute vector for a given type equals to the number of distinct values of that type.
	The elements in an entity's attribute vector equal to the normalized values of the corresponding attributes. \FIXME{ZW: This sentence is confusing. Please consider rephrasing.}
    Because not all entities contain all the attribute types, we pad missing attributes with a value of 0 to form a constant-sized  vector.

 \subsubsection{ii. Node relation}
 Like standard \GCNs, we capture the relation of graph neighboring nodes using an adjacency matrix.
 In our case, the adjacency matrices, $A=\{A_1,A_2,...,A_R |A_i \in \mathbb{R}^{N
 \times N} \}$, describe the adjacency relationships among $N$ nodes under $R$ different relations of graph $G$.

 To construct an adjacency matrix, $A_r$, for relation $r$ we follow a number of steps. We first extract $R_0$ original
 relations from \KGs, then we add reverse relations in order to pass information from the opposite direction, before we back-propagate the
 information to a network node through a self-referencing loop (for retaining the node's information). Applying these steps results in $R=2R_0+1$ relations. 	
 \FIXME{ZW: We either need a diagram or link this paragraph to Figure~\ref{all}}

 \eparagraph{Calculate the embedding matrix}
 The input for layer $l$ in each of our stacked \RGCNs is a node feature matrix, $X^{(l)}$, of $N$ vectors, where  $X^{(l)} =\{x^{(l)}_1,x^{(l)}_2,...,x^{(l)}_{N}
 |x^{(l)}_{i} \in \mathbb{R}^{d^{(l)}}\}$. Each node feature vector, $x_i$, is updated using forward propagation, and we stack the output of each \RGCN, $x_i^{(l+1)}$
 , to form an embedding matrix, $X^{(l+1)} \in \mathbb{R}^{N \times d^{(l+1)}}$.

   The forward propagation of $x_i^{(l+1)}$ of a \RGCN is formulated as:
	\begin{equation}
	x_i^{(l+1)}=\mathrm{ReLU} (\sum\limits_{r \in R}\sum\limits_{j \in N_i^r}\frac{1}{|N_i^r|}W_r^{(l)}x_j^{(l)})
	\end{equation}
%
%
where $N_i^r$ is the set of neighbor indices of node $i$ under relation $r$, according to normalized adjacency matrix $\hat A_r$; and $\hat
A_r$ is an approximate of spectral convolutions on $A^r$, introduced by ~\cite{Kipf2016Semi}:
	\begin{equation}
	\hat A_r=\hat D_r^{- \frac{1}{2}}(A_r+I)\hat D_r^{- \frac{1}{2}}
	\end{equation}
	where $(\hat D_r)_{jj}=\sum_k(A_r+I)_{jk}$.

	
	\eparagraph{Calculate the weight matrix} For each relation $r$, we construct a weight matrix, $W_r^{(l)} \in \mathbb{R}^{d^{(l+1)}
\times d^{(l)}}$ for the stacked \RGCNs. As a \KG often has over thousands of types of relations, there will be a large amount of network
parameters to learn over, which is likely to lead to overfiting. To minimize the impact of the large parameter size, we employ the basis
decomposition method~\cite{Schlichtkrull2017Modeling} to regularize the weights:
	\begin{equation}
	W_r^{(l)}=\sum\limits_{b=1}^B a_{rb}^{(l)}V_b^{(l)}
	\end{equation}
	where $V_b^{(l)} \in \mathbb{R}^{d^{(l+1)} \times d^{(l)}}$ and $a_{rb}^{(l)}$ is the coefficient of matrix $V_b^{(l)}$ for relation $r$.

As a departure from general \GCNs, our approach applies relation-specific transformations to an edge depending on its type and direction.
Later in the paper, we show that this strategy can better capture the multi-relational data characteristics of real-world \KGs. \FIXME{ZW:
Why do we need this paragraph? I don't know where to put it.}

	
	
%	Since it is the first attempt, we only consider the numerical part of a value, regardless of the unit, that is, we do not insist on normalizing \emph{1.80m} and \emph{180cm}.
%	We leave this for future work.


	\subsubsection{Noise control}
	\label{section:hgcn}
	While stacking \RGCN layers enhances our model's capable in learning neighborhood information from relational steps, it may as well
bring noise from the exponentially increasing number of neighbors. To ensure effective spread of informative and discriminative
neighborhood information, we add to our \RGCN-based model layer-wise gates similar to highway networks~\cite{Srivastava2015Highway}.
%~\cite{Rahimi2018Semi} have successfully introduced highway gates to \GCNs~\cite{Kipf2016Semi} to solve the user geolocation problem.
We use layer-wise highway gates to build a Highway \RGCN (\HRGCN) model where the output of a \HRGCN layer is computed as:
	\begin{equation}
	\begin{split}
	&T(x^{(l)})=\sigma(W_T^{(l)}x^{(l)}+b_T^{(l)}) \\
	&x^{(l+1)}=x^{(l+1)} \cdot T(x^{(l)})+x^{(l)} \cdot (1-T(x^{(l)}))
	\end{split}
	\end{equation}
	where $\sigma$ indicates the sigmoid activation function, $\cdot$ is element-wise multiplication, $W_T^{(l)} \in \mathbb{R}^{d^{(l+1)}
\times d^{(l)}}$ and $b_T^{(l)} \in \mathbb{R}^{d^{(l)} \times 1}$ are the weight matrix and bias vector of transform gate $T(x^{(l)})$.
    In Section~\ref{overall}, we show that the highway gates significantly boost the performance of our \RGCN-based model.
	
	\subsection{Alignment Prediction}
	After \HRGCN layers, we get the hidden representations $\bar{X}$ of all nodes in both \KGs. We then measure the similarity between of two
edges, $e_1$ and $e_2$ from $G_1$ and $G_2$, respectively. The similarity is determined by computing the distance between the hidden
representations of two edges:

	\begin{equation}
	\label{d}
	d(e_1,e_2)=|\bar{x}_{e_1}-\bar{x}_{e_2}|
	\end{equation}
	where $|\cdot|$ is the $l_1$ norm. The distance for equivalent entities is expected to be smaller than the non-equivalent counterparts.
In our experiments, for a entity $e_1$ in $G_1$, we compute the distances between $e_1$ and all the entities in $G_2$. The alignment
process can also be reversed, i.e., from $G_2$ to $G_1$. In Section~\ref{sec:results}, we report the results of both directions of entity
alignment.
	
	A set of pre-aligned entity pairs $\mathbb{L}$ and the set of negative pairs $\mathbb{L'}$  constructed by corrupting $(p, q)$, i.e.
replacing $p$ or $q$ with a randomly chosen entity in $G_1$ or $G_2$ are used for training. To maximize the distance between positive and
negative instances, we use the margin-based loss function: \FIXME{ZW: This paragraph appears from nowhere. Please connect it with the
previous paragraph.}
	\begin{equation}
	L=\sum\limits_{(p,q)\in \mathbb{L}}\sum\limits_{(p',q')\in \mathbb{L'}}\mathrm{max}\{0,d(p,q)-d(p',q')+\gamma\}
	\end{equation}
	$\gamma > 0$ is a margin hyper-parameter separating positive and negative entity alignments.
	
	\subsection{Combination of Semantic and Attribute Embeddings}
    Recall that the node feature vector can be initialized from either semantics (i.e., entity names) or attributes (Section~\ref{subsection:Node
    Representations}). %Following the stack structure in Figure~\ref{all}, we
    As a result, each of the stacked \HRGCNs can be applied to a semantic or an attribute embedding.
	%When we leverage the pre-trained word embeddings to initialize the node feature vectors, we call HRGCNs acting semantic embedding.
%	And when the nodes are initialized by attribute vectors, we call HRGCNs performing attribute embedding.
%	Following the same architecture in Figure~\ref{all}, we do semantic embedding and attribute embedding for $G$ respectively.
%
	We integrate semantic embedding and attribute embedding by defining a combined distance $D$ for aligning entities:
	\begin{equation}
		D(e_1,e_2)=\frac{1}{m}[\omega d_s(e_1,e_2)+(1-\omega)d_a(e_1,e_2)]
	\end{equation}

	where $m$ is the dimension of the new node features produced by \HRGCNs, $\omega$ is a hyper-parameter. $d_s$ and $d_a$ are the distance computed by Eq.~\ref{d} according to semantic embedding and attribute embedding, respectively.
	In our experiments, we set the output dimensions of two models (one for semantic embedding and the other one for attribute embedding) to be the same.
	
	
