


	\section{Experiment Results}
	
	%when the available clues for alignment are sparse, we have performed comparative evaluation of our model against several baselines.
	
	
	\subsection{Overall Performance}
    Table~\ref{f1} reports the performance of all models on the WBD dataset. TransE$'$ outperforms JE regarding all the Hits@k measures and outperforms GCN for Hits@1. This indicates that ITransE is an
outstanding model for entity alignment and it also shows that TransE can effectively embed the structure information of KGs which plays an
important role in entity alignment. However, GCN-based model performs better than ITransE in Hits@10 and Hits@50. As aforementioned, GCNs
leverage convolutional layers to characterize an entity through careful investigations about its neighbors, including both neighboring
entities and attribute values, which can provide more fine-grained and accurate modeling and representation for the target entity.
	\begin{table}
		\centering
    \small
		\begin{tabular}{lrrr}
			\toprule
			\bf Models & Hits@1 & Hits@10 & Hits@50 \\
			\midrule
			JE & 10.8 & 21.6 & 31.2 \\
			ITransE$'$ & 25.5 & 34.5 & 46.9 \\
			GCN & 23.2 & 36.3 & 48.8 \\
			\bf RGCN & 34.8 & 49.2 & 61.5 \\
			\bf HRGCN (w/o $X$) & 21.1 & 30.7 & 42.7  \\
			\bf HRGCN & \bf 65.1 & \bf 71.7 & \bf 76.3 \\
			\bottomrule
		\end{tabular}
		\caption{Results comparison of entity alignment.}
		\label{f1}
	\end{table}
	Comparing with GCN, the RGCN-based model further boosts the performance by 11.6\%, 12.9\% and 12.7\% for Hits@1, Hits@10 and Hits@50. It shows that introducing highly multi-relational information to GCN framework can achieve significant improvements on KG embedding.
	
	Among all models, when enhanced with layer-wise highway gates, our HRGCN model performs the best, significantly improving upon RGCN by 30.3\%, 22.5\% and 14.8\% for Hits@1, Hits@10 and Hits@50. This indicates that highway gates play a significant role in our model.
	
	When comparing our full model HRGCN with HRGCN (w/o $X$), we find that removing the predefined input feature matrix $X$ leads to a drop of 44.0\% for Hits@1, 41.0\% for Hits@10 and 33.6\% for Hits@50. This confirms that initializing entity representations using pre-trained word embeddings and normalized value vectors is very helpful in aligning entities from different KGs.
	
	
	%(1) The JE model outperforms the TextSim model and MLP model by 7.6\% and 4.1\%, respectively. This indicates that TransE can effectively embed the structure information of KGs which plays an important role in entity alignment. And it also suggests that the semantic information about the surface forms of entities or values can only play a supporting role, we can't rely on it completely to get the desired result.
	
	
	\subsection{Analysis}
	\begin{figure}
		\begin{center}
			\includegraphics[width=1\linewidth]{figures/graph4.pdf}
			\caption{Hits@1 of ITransE, GCN and HRGCN on the five subsets. 0$\sim$3 denotes the subset in which the number of neighbors differs from 0 to 3 for each entity pair, and similar for the remaining subsets.}
			\label{subset}
		\end{center}
	\end{figure}
	\begin{table*}
		\centering
		\small
		\begin{tabular}{ccccc}
			\toprule
			\multirow{2}{*}{Aligned Entities} & \#Neighbors & \#Similar & \#Values & \#Similar \\
			& Wiki \& Baidu & Neighbors & Wiki \& Baidu & Values \\
			\midrule
			Deng Jiaxian & 10 \& 33 & 5 & \ 3 \& 11 & 2\\
			Hubei Province & 21 \& 50 & 5 & 10 \& 19 & 3\\
			European Union & 66 \& 35 & 6 & 18 \& 8\ \ \ & 2\\
			%Huazhong University of & \multirow{2}{*}{11 \& 32} & \multirow{2}{*}{4} & \multirow{2}{*}{8 \& 6} & \multirow{2}{*}{1}\\
			%Science and Technology & & & & \\
			%Huazhong University of Science and Technology & 11 \& 32 & 4 & 8 \& 6 & 1 \\
			Confucius & 10 \& 20 & 4 & 7 \& 3 & 2\\
			\bottomrule
		\end{tabular}
		\caption{The statistics of example entity pairs, which our HRGCN model correctly aligns but ITransE fails.}
		\label{example}
	\end{table*}
	%An extra advantage of GCN is that we can stack multiple convolution layers to capture more global and larger contextual and neighboring characteristics
	
	We further provide a detailed analysis about the experimental results.
	
	We divide the test set into five subsets according to the difference between the number of neighbors of each entity pair, and compare the performance (in Hits@1) of ITransE, GCN and HRGCN on the five subsets.
	%Figure~\ref{subset} shows the $\mathrm{F}_1$ scores of on the five subsets.
	
	As shown in Figure~\ref{subset}, we can see that when the number of neighbors differs by no more than 3, all three models perform well,
	but when the difference between the entity pairs' neighborhoods becomes more prominent,
	our HRGCN model tends to deliver more clear improvement.
	%, the three models all perform well and the scores are not far-off. However, when the difference in the number of neighbors gradually increases, the gap between JE and the other two models also grows.

	\begin{figure}
		\begin{center}
			\includegraphics[width=1\linewidth]{figures/graph3.pdf}
			\caption{The effect of adding more RGCN layers in terms of Hits@1 over the test set of WBD with and without the highway gates.}
			\label{highway}
		\end{center}
	\end{figure}
	We randomly choose some examples that our HRGCN model can correctly align but ITransE fails in Table~\ref{example}, as well as their neighbor information, i.e., number of neighbors, number of values, number of potentially overlapped neighbors or values for each pair.
	We can find that although several entities have dozens of neighbors in their corresponding KGs, but their similar or overlapped neighbors are quite few, showing again that
	%the number of similar neighbors of these entity pairs is no more than 6 which is very small compared to the number of their neighbors. This indicates that
	the available clues for entity alignment are sparse and ITransE may not perform well in this circumstance, while our HRGCN model can still identify useful structure information from those limited clues.
	
	%Overall, GCNs appear to be more beneficial for structure embedding than TransE, especially when the neighborhoods are very different.
	We can also observe from Table~\ref{example} that values play an important role in entity alignment.
	For instance, in the entity pair about \textit{Hubei Province}, nearly half of the neighbors for each entity are values, and among all 5 similar neighbors, 3 of them are are actually values,
	which provide crucial supporting evidence for the final prediction. Unfortunately, ITransE does not utilize those information, thus is unable to collect sufficient evidence.
	%	While the crucial information obtained from values can not be used by JE since the model dose not consider the specific values.

	
	In Figure~\ref{subset}, we can see that our HRGCN wins GCN in every subset.
	This is mainly because introducing highly multi-relational information to GCN with highway gates can help our model better embed the relational structure information and focus on the most discriminative aspects from the target entity's neighbors, thus lead to more accurate representations.
	%Figure~\ref{fig:heatmap} shows the heat maps about \textit{Centaur}'s neighbors similarities in two KGs, learned by GATs and GCNs-two, respectively.We can observe that GATs can effectively identify the potentially more similar neighbors from two KGs, which will act as discriminative evidence to support the alignment, while GCNs-two fails to distinguish those similar/discriminative neighbors from other non-relevant nodes.
		
	
	%(3) Among all models, the GAT-based model performs the best, improving upon GCNs by a margin of 1.5\%. This indicates that introducing the attention mechanism can more accurately embed the structure information. Figure~\ref{fig:heatmap} is the heat maps which show the similarities of the neighbors' embeddings (learned by GATs/GCNs) of ``Centaur'' from two KGs. We can observe that GATs effectively find the similar neighbors and there is a good distinction in the degree of similarity. However, GCNs treat them the same and the crucial similar nodes are not prominent.

	Adding more HRGCN layers can help the center entities obtain information from neighbors that are multiple hops away. However, it might also introduce noisy information from the exponentially increasing neighbors, leading to significant decline in performance as shown in Figure~\ref{highway} when no highway gates are used. We can observe that the performance of two-layered RGCNs with highway gates improves upon one-layered RGCN. Then by adding more layers the performance of highway RGCNs decreased slowly, but much slower than RGCNs without gates. This confirms that the highway gates effectively control the required balance of neighbor information transmission in RGCNs.
	
